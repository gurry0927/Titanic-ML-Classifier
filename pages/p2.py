import io, joblib
import streamlit as st
import numpy as np
import pandas as pd
from sklearn.tree import plot_tree, DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, auc, roc_curve, roc_auc_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="Titanic ML æ¨¡å‹èª¿åƒå¹³å°",
    page_icon="ğŸš¢",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– session_state
default_keys = ["smote_toggle", "pca_toggle", "standard_toggle", "model_trained"]
for key in default_keys:
    if key not in st.session_state:
        st.session_state[key] = False

# å¿«å–è³‡æ–™è¼‰å…¥
@st.cache_data
def load_data():
    try:
        df = pd.read_csv('datas/train_processed.csv')
        test = pd.read_csv('datas/test_cleaned.csv')
        answer = pd.read_csv('datas/gender_submission.csv')
        return df, test, answer
    except FileNotFoundError:
        st.error("âŒ æ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆï¼Œè«‹ç¢ºèªæª”æ¡ˆè·¯å¾‘æ˜¯å¦æ­£ç¢º")
        st.stop()

# è¼‰å…¥è³‡æ–™
df, test, answer = load_data()
X = df.drop(['Survived'], axis=1)
y = df['Survived']

# å®šç¾©æ¨¡å‹è¨“ç·´å‡½æ•¸
def fit_model(TEST_SIZE, STRATIFY_mode, RANDOM_STATE, 
              SMOTE_mode, PCA_mode, STANDARD_MODE, 
              select_model, cv, SCORING="roc_auc"):
    
    # åˆ†å‰²è³‡æ–™é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=TEST_SIZE,
        stratify=STRATIFY_mode, 
        random_state=RANDOM_STATE
    )

    # è¨­å®šæ¨¡å‹åƒæ•¸
    models_param_grid = {
        "Random Forest": {
            "model": RandomForestClassifier(random_state=RANDOM_STATE),
            "params": {
                "clf__n_estimators": [100, 200],
                "clf__max_depth": [None, 3, 5],
                "clf__min_samples_split": [2, 5]
            }
        },
        "SVC": {
            "model": SVC(probability=True),
            "params": [
                {"clf__C": [0.5, 1, 1.5, 2],
                 "clf__gamma": [0.01, 0.1, 0.15], 
                 "clf__kernel": ["rbf"]}
            ]
        }
    }

    # å»ºç«‹pipeline
    steps = []
    if SMOTE_mode:
        steps.append(("smote", SMOTE(random_state=42)))
    if STANDARD_MODE:
        steps.append(("scaler", StandardScaler()))
    if PCA_mode:
        pca = PCA(n_components=min(2, X.shape[1]))
        steps.append(("pca", pca))
    steps.append(("clf", models_param_grid[select_model]["model"]))

    pipe = Pipeline(steps)

    # GridSearchCV
    param_grid = models_param_grid[select_model]["params"]
    cv_splitter = StratifiedKFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)
    gs = GridSearchCV(
        estimator=pipe,
        param_grid=param_grid,
        cv=cv_splitter,
        scoring=SCORING,
        n_jobs=-1
    )
    gs.fit(X_train, y_train)

    # è¨“ç·´æ±ºç­–æ¨¹ç”¨æ–¼å¯è¦–åŒ–
    clf2 = DecisionTreeClassifier(max_depth=3, random_state=RANDOM_STATE)
    clf2.fit(X_train, y_train)
    
    # é æ¸¬
    y_pred = gs.predict(X_test)
    y_proba = gs.predict_proba(X_test)[:, 1]
    
    # è©•ä¼°
    accuracy = accuracy_score(y_test, y_pred)
    roc_auc_ = roc_auc_score(y_test, y_proba)
    
    # Kaggleé æ¸¬
    y_test_pred = gs.predict(test)
    submission = pd.DataFrame({
        'PassengerId': answer['PassengerId'],
        'Survived': y_test_pred,
    })
    
    return gs, clf2, X_train, y_train, X_test, y_test, y_pred, y_proba, accuracy, roc_auc_, submission

# ============ å´é‚Šæ¬„ - åƒæ•¸è¨­å®šå€ ============
with st.sidebar:
    st.header("âš™ï¸ æ¨¡å‹åƒæ•¸è¨­å®š")
    
    # æ¨¡å‹é¸æ“‡
    select_model = st.selectbox(
        "ğŸ¤– é¸æ“‡æ¨¡å‹:", 
        ('Random Forest', 'SVC'), 
        index=0,
        help="Random Forest: éš¨æ©Ÿæ£®æ— | SVC: æ”¯æ´å‘é‡æ©Ÿ"
    )
    
    st.divider()
    
    # åŸºæœ¬è¨­å®š
    st.subheader("ğŸ¯ åŸºæœ¬è¨­å®š")
    RANDOM_STATE = st.slider(
        "ğŸ² éš¨æ©Ÿç¨®å­", 
        min_value=350, max_value=450, value=421, step=1,
        help="æ§åˆ¶æ¨¡å‹è¨“ç·´çš„éš¨æ©Ÿæ€§ï¼Œç¢ºä¿çµæœé‡ç¾"
    )
    TEST_SIZE = st.slider(
        "ğŸ“Š æ¸¬è©¦é›†ä½”æ¯”", 
        min_value=0.1, max_value=0.5, value=0.25, step=0.05,
        help="ç”¨æ–¼æ¸¬è©¦çš„è³‡æ–™æ¯”ä¾‹"
    )
    cv_splits = st.slider(
        "ğŸ”„ äº¤å‰é©—è­‰æŠ˜æ•¸", 
        min_value=2, max_value=10, value=3, step=1,
        help="K-foldäº¤å‰é©—è­‰çš„æŠ˜æ•¸"
    )
    
    st.divider()
    
    # è³‡æ–™è™•ç†è¨­å®š
    st.subheader("ğŸ› ï¸ è³‡æ–™è™•ç†")
    STRATIFY = st.checkbox(
        "âš–ï¸ ä¾æ¯”ä¾‹åˆ‡å‰²è³‡æ–™é›†", 
        value=True,
        help="ä¿æŒè¨“ç·´/æ¸¬è©¦é›†ä¸­å„é¡åˆ¥çš„æ¯”ä¾‹ä¸€è‡´"
    )
    SMOTE_mode = st.checkbox(
        "ğŸ”„ ä½¿ç”¨SMOTEå¹³è¡¡è³‡æ–™é›†", 
        value=False, key='smote_toggle',
        help="åˆæˆå°‘æ•¸é¡åˆ¥æ¨£æœ¬ï¼Œè§£æ±ºæ¨£æœ¬ä¸å¹³è¡¡å•é¡Œ"
    )
    STANDARD_MODE = st.checkbox(
        "ğŸ“ ä½¿ç”¨æ¨™æº–åŒ–", 
        value=False, key='standard_toggle',
        help="å°‡ç‰¹å¾µç¸®æ”¾è‡³æ¨™æº–æ­£æ…‹åˆ†ä½ˆ"
    )
    PCA_mode = st.checkbox(
        "ğŸ“‰ ä½¿ç”¨PCAé™ç¶­", 
        value=False, key='pca_toggle',
        help="é™è‡³2ç¶­ï¼Œç”¨æ–¼è¦–è¦ºåŒ–åˆ†æ"
    )
    
    st.divider()
    
    # åƒæ•¸èªªæ˜
    with st.expander("â“ åƒæ•¸èªªæ˜"):
        st.markdown("""
        **ğŸ“š æŠ€è¡“èªªæ˜**:
        - **SMOTE**: åˆæˆå°‘æ•¸é¡éæ¡æ¨£æŠ€è¡“
        - **æ¨™æº–åŒ–**: StandardScaleræ­£è¦åŒ–
        - **PCA**: ä¸»æˆåˆ†åˆ†æé™ç¶­
        - **Stratify**: åˆ†å±¤æŠ½æ¨£ä¿æŒæ¯”ä¾‹
        """)
    
    # è¨“ç·´æŒ‰éˆ•
    start = st.button(
        "ğŸš€ é–‹å§‹è¨“ç·´æ¨¡å‹", 
        type="primary", 
        use_container_width=True
    )

# è¨­å®š STRATIFY_mode
STRATIFY_mode = y if STRATIFY else None

# ============ ä¸»é é¢ ============
# æ¨™é¡Œå€åŸŸ
st.title("ğŸš¢ Titanic ç”Ÿå­˜é æ¸¬æ¨¡å‹èª¿åƒ")

# ä¸»è¦å…§å®¹åˆ†é 
tab1, tab2, tab3 = st.tabs(["ğŸ› ï¸ è³‡æ–™é è™•ç†æµç¨‹", "ğŸ“ˆ æ¨¡å‹çµæœ", "ğŸ’¾ æ¨¡å‹ä¸‹è¼‰"])
# ============ Tab 2: è³‡æ–™è™•ç†æµç¨‹ ============
with tab1:
    st.subheader("ğŸ› ï¸ è³‡æ–™æ¸…ç†èˆ‡é è™•ç†æµç¨‹")
    
    # æµç¨‹åœ–ç‰‡
    try:
        st.image('images/data_cleaned.png', caption="è³‡æ–™æ¸…ç†æµç¨‹åœ–",  width=600)
    except:
        st.warning("âš ï¸ æ‰¾ä¸åˆ°æµç¨‹åœ–ç‰‡ (images/data_cleaned.png)")
    
    # è©³ç´°æ­¥é©Ÿ
    with st.expander("ğŸ” æŸ¥çœ‹è©³ç´°è³‡æ–™æ¸…ç†æ­¥é©Ÿ", expanded=True):
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.code('''
                    # === è³‡æ–™æ¸…ç†å®Œæ•´æµç¨‹ ===

                    # 1. åˆªé™¤ä¸ç›¸é—œæ¬„ä½
                    df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
                    # åŸå› ï¼š
                    # - PassengerId: ä¸å½±éŸ¿ç”Ÿå­˜ç‡
                    # - Name, Ticket: é¡åˆ¥éå¤šï¼Œç·¨ç¢¼æ™‚é–“æˆæœ¬é«˜
                    # - Cabin: ç¼ºå¤±å€¼éå¤š (è¿‘80%)

                    # 2. å¡«è£œç¼ºå¤±å€¼
                    df['Age'].fillna(df['Age'].mean(), inplace=True)
                    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
                    # ç­–ç•¥ï¼šæ•¸å€¼å‹ç”¨å¹³å‡å€¼ï¼Œé¡åˆ¥å‹ç”¨çœ¾æ•¸

                    # 3. é¡åˆ¥ç‰¹å¾µç·¨ç¢¼
                    sex_mapping = {'male': 0, 'female': 1}
                    embarked_mapping = {'C': 0, 'Q': 1, 'S': 2}

                    df['Sex'] = df['Sex'].map(sex_mapping).astype(int)
                    df['Embarked'] = df['Embarked'].map(embarked_mapping).astype(int)
            ''', language='python')
        
        with col2:
            st.info("**âœ… è™•ç†æ•ˆæœ**")
            st.success("ğŸ—‘ï¸ ç§»é™¤ç„¡é—œç‰¹å¾µ")
            st.success("ğŸ”§ å¡«è£œç¼ºå¤±å€¼")  
            st.success("ğŸ”¢ ç‰¹å¾µç·¨ç¢¼å®Œæˆ")
            st.success("ğŸ“Š è³‡æ–™æ¸…ç†å®Œç•¢")

        cols1, cols2, cols3, cols4 = st.columns([1,1,1,1])    
        with cols1:
            st.info("**æ¸…ç†å¾Œçµ±è¨ˆï¼š**")
        with cols2:
            st.metric("ç‰¹å¾µæ•¸é‡", len(df.columns)-1)
        with cols3:
            st.metric("æ¨£æœ¬æ•¸é‡", len(df))
        with cols4:
            st.metric("ç¼ºå¤±å€¼", df.isnull().sum().sum())

# ============ Tab 3: æ¨¡å‹çµæœ ============
with tab2:
    if start:
        with st.spinner("ğŸš€ æ¨¡å‹è¨“ç·´ä¸­ï¼Œè«‹ç¨å€™..."):
            try:
                gs, clf2, X_train, y_train, X_test, y_test, y_pred, y_proba, accuracy, roc_auc_, submission = fit_model(
                    TEST_SIZE, STRATIFY_mode, RANDOM_STATE, SMOTE_mode, 
                    PCA_mode, STANDARD_MODE, select_model, cv_splits, SCORING="roc_auc"
                )
                st.session_state.model_trained = True
                st.session_state.gs = gs
                st.session_state.submission = submission
                st.session_state.clf2 = clf2
                st.session_state.X_train = X_train
                st.session_state.y_train = y_train
                st.session_state.X_test = X_test
                st.session_state.y_test = y_test
                st.session_state.y_pred = y_pred
                st.session_state.y_proba = y_proba
                st.session_state.accuracy = accuracy
                st.session_state.roc_auc_ = roc_auc_
                
            except Exception as e:
                st.error(f"âŒ æ¨¡å‹è¨“ç·´å¤±æ•—: {str(e)}")
                st.stop()
        
        st.success("âœ… æ¨¡å‹è¨“ç·´å®Œæˆï¼")
    
    if st.session_state.model_trained:
        st.subheader("ğŸ“ˆ æ¨¡å‹è¨“ç·´çµæœ")
        
        # æœ€ä½³åƒæ•¸å±•ç¤º
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"**ğŸ† æ¨¡å‹é¸æ“‡**: {select_model}")
        with col2:
            best_params = pd.DataFrame(st.session_state.gs.best_params_, index=[0]).T
            best_params.columns = ['æœ€ä½³åƒæ•¸å€¼']
            st.dataframe(best_params, use_container_width=True)
        
        # æ•ˆèƒ½ç¸½è¦½
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ¯ æº–ç¢ºç‡", f"{st.session_state.accuracy:.3f}")
        with col2:
            st.metric("ğŸ“Š ROC AUC", f"{st.session_state.roc_auc_:.3f}")
        with col3:
            st.metric("ğŸ”„ CVæŠ˜æ•¸", cv_splits)
        
        # è©³ç´°è©•ä¼°çµæœ
        eval_tab1, eval_tab2, eval_tab3, eval_tab4, eval_tab5, eval_tab6 = st.tabs([
            "ğŸ“Š åˆ†é¡å ±å‘Š", "ğŸ“ˆ ROCæ›²ç·š", "ğŸ¯ æ··æ·†çŸ©é™£", "ğŸ” PCAæ•£ä½ˆåœ–", "ğŸ“‹ Kaggleé æ¸¬", "ğŸŒ³ ç‰¹å¾µé‡è¦æ€§"
        ])
        
        with eval_tab1:  # åˆ†é¡å ±å‘Š
            st.subheader("ğŸ“Š è©³ç´°åˆ†é¡å ±å‘Š")
            class_report = classification_report(
                st.session_state.y_test, st.session_state.y_pred, 
                output_dict=True, target_names=["Dead(0)", "Alive(1)"]
            )
            class_report_df = pd.DataFrame(class_report).transpose().round(2)
            st.dataframe(class_report_df, use_container_width=True)
            
        with eval_tab2:  # ROCæ›²ç·š
            st.subheader("ğŸ“ˆ ROCæ›²ç·šåˆ†æ")
            fpr, tpr, thresholds = roc_curve(st.session_state.y_test, st.session_state.y_proba)
            roc_auc = auc(fpr, tpr)
            
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.plot(fpr, tpr, color="darkorange", lw=2, label=f"ROC curve (AUC = {roc_auc:.3f})")
            ax.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--")
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel("False Positive Rate")
            ax.set_ylabel("True Positive Rate")
            ax.set_title("Receiver Operating Characteristic (ROC)")
            ax.legend(loc="lower right")
            ax.grid(True, alpha=0.3)
            st.pyplot(fig, use_container_width=True)
            
        with eval_tab3:  # æ··æ·†çŸ©é™£
            st.subheader("ğŸ¯ æ··æ·†çŸ©é™£")
            conf_matrix = confusion_matrix(st.session_state.y_test, st.session_state.y_pred)
            
            fig, ax = plt.subplots(figsize=(8, 5))
            sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", ax=ax)
            ax.set_xlabel("Predicted")
            ax.set_ylabel("Actual")
            ax.set_xticklabels(["Dead", "Alive"])
            ax.set_yticklabels(["Dead", "Alive"])
            ax.set_title("Confusion Matrix")
            st.pyplot(fig, use_container_width=True)
            
            # æ··æ·†çŸ©é™£è§£è®€
            tn, fp, fn, tp = conf_matrix.ravel()
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("âœ… True Negative", tn)
            with col2:
                st.metric("âŒ False Positive", fp)
            with col3:
                st.metric("âŒ False Negative", fn)
            with col4:
                st.metric("âœ… True Positive", tp)
        
        with eval_tab4:  # PCAæ•£ä½ˆåœ–
            st.subheader("ğŸ” PCAäºŒç¶­æ•£ä½ˆåœ–")
            if PCA_mode:
                pca = PCA(n_components=2)
                X_pca = pca.fit_transform(X)
                pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])
                pca_df['Target'] = y.values
                
                fig, ax = plt.subplots(figsize=(8, 5))
                sns.scatterplot(
                    data=pca_df,
                    x="PC1", y="PC2",
                    hue="Target",
                    palette="Set1",
                    alpha=0.7,
                    ax=ax
                )
                ax.set_title("PCA 2D Scatter Plot")
                ax.grid(True, alpha=0.3)
                st.pyplot(fig, use_container_width=True)
                
                # PCAè§£é‡‹
                explained_variance = pca.explained_variance_ratio_
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("PC1 è§£é‡‹è®Šç•°", f"{explained_variance[0]:.3f}")
                with col2:
                    st.metric("PC2 è§£é‡‹è®Šç•°", f"{explained_variance[1]:.3f}")
                with col3:
                    st.metric("ç¸½è§£é‡‹è®Šç•°", f"{explained_variance.sum():.3f}")
            else:
                st.warning("âš ï¸ è«‹åœ¨å·¦å´å•Ÿç”¨PCAé¸é …ä»¥é¡¯ç¤ºæ•£ä½ˆåœ–")
        
        with eval_tab5:  # Kaggleé æ¸¬
            st.subheader("ğŸ“‹ Kaggleæ¸¬è©¦é›†é æ¸¬çµæœ")
            st.info("**å‰5ç­†é æ¸¬çµæœé è¦½**")
            st.dataframe(st.session_state.submission.head(), use_container_width=True)
            
            # é æ¸¬çµ±è¨ˆ
            pred_stats = st.session_state.submission['Survived'].value_counts()
            survival_pred_rate = st.session_state.submission['Survived'].mean()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ’€ é æ¸¬æ­»äº¡", pred_stats[0])
            with col2:
                st.metric("â¤ï¸ é æ¸¬ç”Ÿå­˜", pred_stats[1])
            with col3:
                st.metric("ğŸ¯ é æ¸¬ç”Ÿå­˜ç‡", f"{survival_pred_rate:.2%}")
        
        with eval_tab6:  # ç‰¹å¾µé‡è¦æ€§
            st.subheader("ğŸŒ³ æ¨¡å‹å¯è§£é‡‹æ€§åˆ†æ")
            
            if select_model == 'Random Forest':
                best_est = st.session_state.gs.best_estimator_
                rf = best_est.named_steps['clf']
                
                # ç¢ºå®šç‰¹å¾µåç¨±
                if 'pca' in best_est.named_steps:
                    n_comp = best_est.named_steps['pca'].n_components_
                    feature_names = [f'PC{i+1}' for i in range(n_comp)]
                else:
                    feature_names = list(st.session_state.X_train.columns)
                
                # ç‰¹å¾µé‡è¦æ€§åœ–
                imp = pd.Series(rf.feature_importances_, index=feature_names).sort_values(ascending=True)
                
                fig1, ax1 = plt.subplots(figsize=(10, 6))
                bars = ax1.barh(imp.index, imp.values, color='skyblue')
                ax1.set_xlabel("Feature Importance")
                ax1.set_title("Random Forest Feature Importance")
                ax1.grid(True, alpha=0.3)
                
                # åœ¨æŸ±ç‹€åœ–ä¸Šé¡¯ç¤ºæ•¸å€¼
                for i, bar in enumerate(bars):
                    width = bar.get_width()
                    ax1.text(width + 0.01, bar.get_y() + bar.get_height()/2, 
                            f'{width:.3f}', ha='left', va='center')
                
                st.pyplot(fig1, use_container_width=True)
                
                # æ±ºç­–æ¨¹å¯è¦–åŒ–
                with st.expander("ğŸŒ² æ±ºç­–æ¨¹è¦–è¦ºåŒ– (è£œå……èªªæ˜)", expanded=False):
                    st.info("**ğŸ“– èªªæ˜**: ä»¥ä¸‹ç‚ºå–®ä¸€æ±ºç­–æ¨¹(æ·±åº¦=3)ï¼Œç”¨æ–¼è§£é‡‹æ±ºç­–é‚è¼¯")
                    
                    fig2, ax2 = plt.subplots(figsize=(20, 12))
                    plot_tree(
                        st.session_state.clf2,
                        feature_names=list(st.session_state.X_train.columns),
                        class_names=['Dead', 'Alive'],
                        filled=True,
                        impurity=False,
                        rounded=True,
                        ax=ax2,
                        fontsize=10
                    )
                    ax2.set_title("Decision Tree Visualization (max_depth=3)", fontsize=16)
                    st.pyplot(fig2, use_container_width=True)
                    
            else:
                st.warning("âš ï¸ ç‰¹å¾µé‡è¦æ€§åˆ†æåƒ…æ”¯æ´Random Forestæ¨¡å‹")
    else:
        # æœªè¨“ç·´ç‹€æ…‹çš„æç¤º
        st.info("""
        ### ğŸ¯ é–‹å§‹æ¨¡å‹è¨“ç·´
        
        **å·²é…ç½®æ¨è–¦åƒæ•¸ï¼Œé»æ“Šå·¦å´ã€Œé–‹å§‹è¨“ç·´æ¨¡å‹ã€å³å¯æŸ¥çœ‹å®Œæ•´åˆ†æçµæœ**
        

        """)

# ============ Tab 4: æ¨¡å‹ä¸‹è¼‰ ============
with tab3:
    if st.session_state.model_trained:
        st.subheader("ğŸ’¾ æ¨¡å‹èˆ‡çµæœä¸‹è¼‰")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.info("**ğŸ¤– è¨“ç·´å¥½çš„æ¨¡å‹**")
            st.markdown("""
            **åŒ…å«å…§å®¹**:
            - âœ… æœ€ä½³åƒæ•¸é…ç½®
            - âœ… å®Œæ•´é è™•ç†pipeline
            - âœ… è¨“ç·´å¥½çš„åˆ†é¡å™¨
            """)
            
            # ä¸‹è¼‰æ¨¡å‹
            buf = io.BytesIO()
            joblib.dump(st.session_state.gs.best_estimator_, buf)
            buf.seek(0)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰æœ€ä½³æ¨¡å‹ (.joblib)",
                data=buf,
                file_name=f"best_{select_model.lower().replace(' ', '_')}_model.joblib",
                mime="application/octet-stream",
                use_container_width=True
            )
            
        with col2:
            st.info("**ğŸ“Š Kaggleæäº¤æª”æ¡ˆ**")
            st.markdown("""
            **æª”æ¡ˆæ ¼å¼**:
            - âœ… ç¬¦åˆKaggleæäº¤è¦æ±‚
            - âœ… PassengerId + Survived
            - âœ… å¯ç›´æ¥ä¸Šå‚³ç«¶è³½
            """)
            
            # ä¸‹è¼‰CSV
            csv_buf = io.BytesIO()
            st.session_state.submission.to_csv(csv_buf, index=False)
            csv_buf.seek(0)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰é æ¸¬çµæœ (.csv)",
                data=csv_buf,
                file_name=f"titanic_submission_{select_model.lower().replace(' ', '_')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        # æ¨¡å‹æ‘˜è¦è³‡è¨Š
        st.markdown("---")
        with st.expander("ğŸ“‹ æ¨¡å‹è¨“ç·´æ‘˜è¦", expanded=True):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("**ğŸ”§ æ¨¡å‹é…ç½®**")
                st.write(f"â€¢ æ¨¡å‹: {select_model}")
                st.write(f"â€¢ éš¨æ©Ÿç¨®å­: {RANDOM_STATE}")
                st.write(f"â€¢ æ¸¬è©¦é›†æ¯”ä¾‹: {TEST_SIZE}")
                st.write(f"â€¢ CVæŠ˜æ•¸: {cv_splits}")
                
            with col2:
                st.markdown("**âš™ï¸ é è™•ç†æ­¥é©Ÿ**")
                st.write(f"â€¢ åˆ†å±¤æŠ½æ¨£: {'âœ…' if STRATIFY else 'âŒ'}")
                st.write(f"â€¢ SMOTEå¹³è¡¡: {'âœ…' if SMOTE_mode else 'âŒ'}")
                st.write(f"â€¢ æ¨™æº–åŒ–: {'âœ…' if STANDARD_MODE else 'âŒ'}")
                st.write(f"â€¢ PCAé™ç¶­: {'âœ…' if PCA_mode else 'âŒ'}")
                
            with col3:
                st.markdown("**ğŸ“Š æ€§èƒ½æŒ‡æ¨™**")
                st.write(f"â€¢ æº–ç¢ºç‡: {st.session_state.accuracy:.3f}")
                st.write(f"â€¢ ROC AUC: {st.session_state.roc_auc_:.3f}")
                st.write(f"â€¢ è¨“ç·´æ¨£æœ¬: {len(st.session_state.X_train)}")
                st.write(f"â€¢ æ¸¬è©¦æ¨£æœ¬: {len(st.session_state.X_test)}")
                
    else:
        st.warning("âš ï¸ è«‹å…ˆå®Œæˆæ¨¡å‹è¨“ç·´å¾Œå†é€²è¡Œä¸‹è¼‰")
        st.info("""
        ### ğŸ“‹ ä¸‹è¼‰åŠŸèƒ½èªªæ˜
        
        å®Œæˆæ¨¡å‹è¨“ç·´å¾Œï¼Œæ‚¨å¯ä»¥ä¸‹è¼‰ï¼š
        
        1. **ğŸ¤– è¨“ç·´å¥½çš„æ¨¡å‹æª”æ¡ˆ** (.joblibæ ¼å¼)
           - åŒ…å«å®Œæ•´çš„é è™•ç†pipelineåƒæ•¸
           - å¯åœ¨å…¶ä»–ç’°å¢ƒä¸­ç›´æ¥ä½¿ç”¨
           - æ”¯æ´joblib.load()è¼‰å…¥
        
        2. **ğŸ“Š Kaggleç«¶è³½æäº¤æª”æ¡ˆ** (.csvæ ¼å¼)
           - ç¬¦åˆå®˜æ–¹æäº¤æ ¼å¼è¦æ±‚
           - åŒ…å«PassengerIdå’ŒSurvivedæ¬„ä½
           - å¯ç›´æ¥ä¸Šå‚³è‡³Kaggleç«¶è³½å¹³å°
        """)

# ============ åº•éƒ¨è³‡è¨Šå€ ============
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666; font-size: 0.8rem;'>
    <p> Tech-Stack: Python â€¢ Scikit-learn â€¢ Streamlit â€¢ Pandas â€¢ Matplotlib â€¢ Github â€¢ Kaggle </p>
    </div>
    """, 
    unsafe_allow_html=True
)

# å´é‚Šæ¬„åº•éƒ¨è³‡è¨Š
with st.sidebar:
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666; font-size: 0.8rem;'>
        <p>ğŸ¯ Machine Learning<br> 
        Model Tuning Platform<br>
        Built with Streamlit</p>
        </div>
        """, 
        unsafe_allow_html=True
    )